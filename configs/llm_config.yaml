provider: openai         # 우선 openai로 시작(원하면 나중에 provider 플러그형으로)
model: "gpt-4o-mini"      # 가볍게 시작
temperature: 0.2
timeout_s: 30
max_tokens: 1200
rate_limit_tpm: 60000
redact_patterns:          # LLM 호출 전 추가 마스킹(방어막)
  - "\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b"     # IPv4
  - "\\b(?:[0-9A-Fa-f]{2}[:\\-]){5}[0-9A-Fa-f]{2}\\b"  # MAC
pass_through_if_shorter_than: 200   # 너무 짧으면 LLM 생략(그대로 템플릿에)
